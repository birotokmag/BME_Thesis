{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV as gscv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and calculate ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-145-983bd4b0ba11>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ratios[y+i+\"mf\"] = df[y+i]/df[y+\"TAH061\"]\n",
      "<ipython-input-145-983bd4b0ba11>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ratios[y+i+\"liab\"] = df[y+i]/(df[y+\"TAH051\"]+df[y+\"TAH054\"])\n",
      "<ipython-input-145-983bd4b0ba11>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ratios[y+i+\"toke\"] = df[y+i]/(df[y+\"TAH001\"]+df[y+\"TAH012\"]+df[y+\"TAH048\"]+df[y+\"TAH189\"]+df[y+\"TAH208\"]+df[y+\"TAH060\"]+df[y+\"TAH179\"]+df[y+\"TAH187\"]+df[y+\"TAH059\"])\n",
      "<ipython-input-145-983bd4b0ba11>:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ratios[y+i+\"kolt\"] = df[y+i]/(df[y+\"TAC002\"]+df[y+\"TAC006\"]-df[y+\"TAC019\"])\n",
      "<ipython-input-145-983bd4b0ba11>:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ratios[y+i+\"arbev\"] = df[y+i]/df[y+\"TAC002\"]\n",
      "<ipython-input-145-983bd4b0ba11>:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cRatios[str(y)+\"c\"+str(y+1)+i+\"mf\"] = (ratios[str(y+1)+i+\"mf\"]-ratios[str(y)+i+\"mf\"])/ratios[str(y)+i+\"mf\"]\n",
      "<ipython-input-145-983bd4b0ba11>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cRatios[str(y)+\"c\"+str(y+1)+i+\"liab\"] = (ratios[str(y+1)+i+\"liab\"]-ratios[str(y)+i+\"liab\"])/ratios[str(y)+i+\"liab\"]\n",
      "<ipython-input-145-983bd4b0ba11>:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cRatios[str(y)+\"c\"+str(y+1)+i+\"toke\"] = (ratios[str(y+1)+i+\"toke\"]-ratios[str(y)+i+\"toke\"])/ratios[str(y)+i+\"toke\"]\n",
      "<ipython-input-145-983bd4b0ba11>:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cRatios[str(y)+\"c\"+str(y+1)+i+\"kolt\"] = (ratios[str(y+1)+i+\"kolt\"]-ratios[str(y)+i+\"kolt\"])/ratios[str(y)+i+\"kolt\"]\n",
      "<ipython-input-145-983bd4b0ba11>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cRatios[str(y)+\"c\"+str(y+1)+i+\"arbev\"] = (ratios[str(y+1)+i+\"arbev\"]-ratios[str(y)+i+\"arbev\"])/ratios[str(y)+i+\"arbev\"]\n"
     ]
    }
   ],
   "source": [
    "nCluster=8\n",
    "df = pd.read_pickle(\"data/dataframe\")\n",
    "yearsString = [\"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\"]\n",
    "arbevetel = [\"TAH197\"]\n",
    "koltseg = [\"TAC008\",\n",
    "\"TAC009\",\"TAC011\",\"TAC010\",\"TAC078\",\"TAH014\",\"TAH015\",\"TAC012\",\"TAC013\",\"TAC014\",\"TAC015\",\"TAC016\",\"TAC018\",\"TAC063\",\"TAH021\",\"TAC109\",\"TAC190\",\"TAC059\",\"TAB024\",\"TAH197\"]\n",
    "merlegfoosszeg=[\"TAH186\",\n",
    "\"TAH230\",\"TAH033\",\"TAH087\",\"TAH088\",\"TAH041\",\"TAH042\",\"TAH231\",\"TAH043\",\"TAH044\",\"TAH232\",\"TAH045\", \"TAH187\", \"TAI001\",\n",
    "\"TAI002\",\"TAI019\",\"TAI020\",\"TAI022\",\"TAI023\",\"TAI041\",\"TAI042\",\"TAI043\",\"TAI044\",\"TAI033\",\"TAH034\",\"TAI045\",\"TAI046\",\"TAI035\",\"TAI047\",\"TAI048\",\"TAI036\",\"TAI049\",\"TAI050\",\"TAI037\",\"TAI051\",\"TAI052\",\"TAI053\",\"TAI054\",\"TAI055\",\"TAI056\",\"TAI057\",\"TAH190\",\"TAI038\",\"TAI058\", \"TAB024\",\"TAH197\"]\n",
    "liabilities = [\"TAH209\",\"TAH051\",\"TAH227\",\"TAH054\",\"TAH055\",\"TAH180\",\"TAH199\"]\n",
    "toke = [\"TAH002\",\"TAH003\",\"TAH004\",\"TAH005\",\"TAH011\",\"TAH007\",\"TAH233\",\"TAH234\",\"TAH012\",\"TAH048\",\"TAH189\",\"TAH208\",\"TAH060\",\"TAH179\",\"TAH187\"]\n",
    "\n",
    "ratios = pd.DataFrame()\n",
    "for y in yearsString:\n",
    "    for i in arbevetel:\n",
    "        ratios[y+i+\"arbev\"] = df[y+i]/df[y+\"TAC002\"]\n",
    "    for i in merlegfoosszeg:\n",
    "        ratios[y+i+\"mf\"] = df[y+i]/df[y+\"TAH061\"]\n",
    "    for i in liabilities:\n",
    "        ratios[y+i+\"liab\"] = df[y+i]/(df[y+\"TAH051\"]+df[y+\"TAH054\"])\n",
    "    for i in toke:\n",
    "        ratios[y+i+\"toke\"] = df[y+i]/(df[y+\"TAH001\"]+df[y+\"TAH012\"]+df[y+\"TAH048\"]+df[y+\"TAH189\"]+df[y+\"TAH208\"]+df[y+\"TAH060\"]+df[y+\"TAH179\"]+df[y+\"TAH187\"]+df[y+\"TAH059\"])\n",
    "    for i in koltseg:\n",
    "        ratios[y+i+\"kolt\"] = df[y+i]/(df[y+\"TAC002\"]+df[y+\"TAC006\"]-df[y+\"TAC019\"])\n",
    "ratios = ratios.replace(np.inf, 0)\n",
    "ratios = ratios.replace(-np.inf, 0)        \n",
    "ratios.fillna(0, inplace=True)\n",
    "        \n",
    "cRatios = pd.DataFrame()\n",
    "for y in range(14, 20):\n",
    "    for i in arbevetel:\n",
    "        cRatios[str(y)+\"c\"+str(y+1)+i+\"arbev\"] = (ratios[str(y+1)+i+\"arbev\"]-ratios[str(y)+i+\"arbev\"])/ratios[str(y)+i+\"arbev\"]\n",
    "    for i in merlegfoosszeg:\n",
    "        cRatios[str(y)+\"c\"+str(y+1)+i+\"mf\"] = (ratios[str(y+1)+i+\"mf\"]-ratios[str(y)+i+\"mf\"])/ratios[str(y)+i+\"mf\"]\n",
    "    for i in liabilities:\n",
    "        cRatios[str(y)+\"c\"+str(y+1)+i+\"liab\"] = (ratios[str(y+1)+i+\"liab\"]-ratios[str(y)+i+\"liab\"])/ratios[str(y)+i+\"liab\"]\n",
    "    for i in toke:\n",
    "        cRatios[str(y)+\"c\"+str(y+1)+i+\"toke\"] = (ratios[str(y+1)+i+\"toke\"]-ratios[str(y)+i+\"toke\"])/ratios[str(y)+i+\"toke\"]\n",
    "    for i in koltseg:\n",
    "        cRatios[str(y)+\"c\"+str(y+1)+i+\"kolt\"] = (ratios[str(y+1)+i+\"kolt\"]-ratios[str(y)+i+\"kolt\"])/ratios[str(y)+i+\"kolt\"]\n",
    "\n",
    "cRatios = cRatios.replace(np.inf, 0)\n",
    "cRatios = cRatios.replace(-np.inf, 0)        \n",
    "cRatios.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodInTime = pd.DataFrame()\n",
    "for i in range(14, 21): \n",
    "    prodInTime[str(i)] = df[str(i)+\"Productivity\"]\n",
    "prodInTime = TimeSeriesScalerMeanVariance().fit_transform(prodInTime)\n",
    "\n",
    "timeSeriesClusterModel = TimeSeriesKMeans(n_clusters=nCluster, metric=\"dtw\", max_iter=10, random_state=15)\n",
    "timeSeriesClusterModel.fit(prodInTime)\n",
    "targetLabels = timeSeriesClusterModel.predict(prodInTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting with SMOTE, change values, RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "gradientResultSmote=[]\n",
    "gradientTestConfM = []\n",
    "gradientTestF1 = []\n",
    "for c in range(0, nCluster):\n",
    "    cRatiosMask = np.load(\"cRatiosRFEMaskC\"+str(c)+\".npy\")\n",
    "    cRatiosCluster = cRatios[cRatios.columns[cRatiosMask]]\n",
    "    trainX, testX, trainY, testY = train_test_split(cRatiosCluster, targetLabels == c, test_size=0.2, random_state=42)\n",
    "    sm = SMOTE(random_state=42)\n",
    "    x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "    parameters = {'n_estimators': [75, 100, 125, 150], 'max_depth':[8, 10, 12, 14, 15]}\n",
    "    gbc = GradientBoostingClassifier(random_state = 40, min_samples_split = 150)\n",
    "    gradientGridSearch = gscv(gbc, parameters, scoring='f1', n_jobs=-1, verbose=4)\n",
    "    gradientGridSearch.fit(x_res, y_res)\n",
    "    gradientResultSmote.append(gradientGridSearch)\n",
    "    gradientTestConfM.append(metrics.confusion_matrix(testY, gradientGridSearch.best_estimator_.predict(testX)))\n",
    "    gradientTestF1.append(metrics.f1_score(testY, gradientGridSearch.best_estimator_.predict(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[2020  231]\n",
      " [ 352  171]]\n",
      "0.36972972972972973\n",
      "[0.81425392 0.82243055 0.82911799 0.83132191 0.82613449 0.83263645\n",
      " 0.83895203 0.84316212 0.83409003 0.84151295 0.84752271 0.85223946\n",
      " 0.84014776 0.84770169 0.85180759 0.85663035 0.84181841 0.84957018\n",
      " 0.85294575 0.8566813 ]\n",
      "{'max_depth': 15, 'n_estimators': 150}\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for c in range(0, nCluster):\n",
    "    print(c)\n",
    "    print(gradientTestConfM[c])\n",
    "    print(gradientTestF1[c])\n",
    "    print(gradientResultSmote[c].cv_results_[\"mean_test_score\"])\n",
    "    print(gradientResultSmote[c].best_params_)\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with SMOTE, change values, RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    }
   ],
   "source": [
    "randomForestResultSmote=[]\n",
    "randomForestTestConfM = []\n",
    "randomForestTestF1 = []\n",
    "for c in range(0, nCluster):\n",
    "    cRatiosMask = np.load(\"cRatiosRFEMaskC\"+str(c)+\".npy\")\n",
    "    cRatiosCluster = cRatios[cRatios.columns[cRatiosMask]]\n",
    "    trainX, testX, trainY, testY = train_test_split(cRatiosCluster, targetLabels == c, test_size=0.2, random_state=42)\n",
    "    sm = SMOTE(random_state=42)\n",
    "    x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "    parameters = {'n_estimators':[4, 5, 6, 7, 8, 9, 10], 'max_depth':[1, 2, 3, 4, 5, 6]}\n",
    "    rfc = RandomForestClassifier()\n",
    "    randomForestSearch = gscv(rfc, parameters, scoring='f1', n_jobs=-1, verbose=4)\n",
    "    randomForestSearch.fit(x_res, y_res)\n",
    "    randomForestResultSmote.append(randomForestSearch)\n",
    "    randomForestTestConfM.append(metrics.confusion_matrix(testY, randomForestSearch.best_estimator_.predict(testX)))\n",
    "    randomForestTestF1.append(metrics.f1_score(testY, randomForestSearch.best_estimator_.predict(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[2099  465]\n",
      " [ 137   73]]\n",
      "0.19518716577540104\n",
      "[0.65588041 0.67687563 0.6283968  0.64589344 0.67789345 0.65863339\n",
      " 0.67429459 0.65917825 0.67993271 0.6894734  0.69136236 0.69784886\n",
      " 0.70121512 0.70862446 0.69756002 0.70101917 0.70768676 0.71215586\n",
      " 0.70601831 0.71235402 0.71198483 0.72523218 0.72988579 0.7311595\n",
      " 0.73413808 0.73404297 0.73382531 0.74082119 0.73715705 0.74869376\n",
      " 0.75374472 0.75593752 0.75419949 0.76275281 0.76486128 0.75475367\n",
      " 0.76695362 0.76979613 0.77660042 0.78201316 0.78521673 0.77993928]\n",
      "--------------\n",
      "1\n",
      "[[1968  516]\n",
      " [ 220   70]]\n",
      "0.1598173515981735\n",
      "[0.59670404 0.59042844 0.59372697 0.61224783 0.62748728 0.63821732\n",
      " 0.62768085 0.63695864 0.64329872 0.65903605 0.63330915 0.65262255\n",
      " 0.63102337 0.64900854 0.65829613 0.65923427 0.69043566 0.68204811\n",
      " 0.68441441 0.69310627 0.69451689 0.6836143  0.69910332 0.70836846\n",
      " 0.6915184  0.7159284  0.70936829 0.71525621 0.70877477 0.7086579\n",
      " 0.71783461 0.71205299 0.7237355  0.74031717 0.73450476 0.73152683\n",
      " 0.74151423 0.72997051 0.73523552 0.73704548 0.74578262 0.75012342]\n",
      "--------------\n",
      "2\n",
      "[[1981  557]\n",
      " [ 140   96]]\n",
      "0.21597300337457817\n",
      "[0.60865618 0.65439465 0.64355207 0.67020675 0.66198785 0.63954997\n",
      " 0.66395464 0.64167188 0.6705228  0.68992406 0.68870168 0.68346349\n",
      " 0.69783735 0.69746285 0.70190176 0.70907362 0.71694349 0.7244849\n",
      " 0.715853   0.70912091 0.7235632  0.72430965 0.73467303 0.74211517\n",
      " 0.74370914 0.73759616 0.74783163 0.74874088 0.7388637  0.75412496\n",
      " 0.75140793 0.76109584 0.76245483 0.76724112 0.76858268 0.745938\n",
      " 0.7585332  0.77111472 0.76997151 0.78560868 0.78419635 0.78411779]\n",
      "--------------\n",
      "3\n",
      "[[1899  516]\n",
      " [ 259  100]]\n",
      "0.20512820512820512\n",
      "[0.61640365 0.53998988 0.58167071 0.60440359 0.61215336 0.59566942\n",
      " 0.6349356  0.60323041 0.64009573 0.62694395 0.6468406  0.64961406\n",
      " 0.63198387 0.64391242 0.64818479 0.66695648 0.65545959 0.66720189\n",
      " 0.66974321 0.67971404 0.66641251 0.67403763 0.66460853 0.67719136\n",
      " 0.6877552  0.68617323 0.69597898 0.69074621 0.67768132 0.68585863\n",
      " 0.69531055 0.7001995  0.70357419 0.71327915 0.70368791 0.70563843\n",
      " 0.70989567 0.71414454 0.71763901 0.72284708 0.71099751 0.72981767]\n",
      "--------------\n",
      "4\n",
      "[[1606  645]\n",
      " [ 229  294]]\n",
      "0.4021887824897401\n",
      "[0.58772994 0.65713964 0.64338846 0.63935483 0.67891827 0.66183347\n",
      " 0.65081672 0.66016845 0.64831543 0.65739852 0.65078676 0.66458535\n",
      " 0.68378242 0.66880112 0.67205039 0.67788703 0.65730727 0.67855952\n",
      " 0.67366146 0.69287304 0.69409169 0.69679599 0.69622059 0.69598776\n",
      " 0.69715612 0.69017854 0.68493892 0.70310003 0.69373705 0.70635903\n",
      " 0.70968484 0.70511612 0.71015188 0.71286995 0.71329942 0.69998303\n",
      " 0.70769545 0.71622563 0.71397104 0.71876878 0.71965638 0.72458338]\n",
      "--------------\n",
      "5\n",
      "[[2028  493]\n",
      " [ 154   99]]\n",
      "0.23431952662721894\n",
      "[0.61862207 0.64351675 0.62575697 0.63413719 0.63274367 0.66816661\n",
      " 0.6557204  0.6667222  0.65377001 0.67268134 0.66090951 0.67655673\n",
      " 0.67975353 0.69034089 0.66839678 0.68346463 0.70554606 0.69529633\n",
      " 0.70923051 0.69619398 0.70352209 0.70923219 0.70263151 0.71826846\n",
      " 0.69888428 0.7233627  0.70933285 0.73015798 0.72780278 0.73387727\n",
      " 0.73652145 0.74443076 0.73370959 0.73893546 0.73741977 0.73216873\n",
      " 0.75072252 0.74754904 0.75249138 0.74131272 0.75439387 0.76116714]\n",
      "--------------\n",
      "6\n",
      "[[2143  397]\n",
      " [ 173   61]]\n",
      "0.1763005780346821\n",
      "[0.61943467 0.61389796 0.63740958 0.62596229 0.65516436 0.66444305\n",
      " 0.67407962 0.6711381  0.69751852 0.67382769 0.69810202 0.70571222\n",
      " 0.67480791 0.69227835 0.70248814 0.69428941 0.70871174 0.72609799\n",
      " 0.71203612 0.72123415 0.73488797 0.73460552 0.72049056 0.7375431\n",
      " 0.74222363 0.74905431 0.74013815 0.73940154 0.74808546 0.75194286\n",
      " 0.75476808 0.75316346 0.76559095 0.7705078  0.76870148 0.76203579\n",
      " 0.76997412 0.77753214 0.77881635 0.79029642 0.78488328 0.79487975]\n",
      "--------------\n",
      "7\n",
      "[[1471  634]\n",
      " [ 307  362]]\n",
      "0.43483483483483487\n",
      "[0.6467497  0.65294769 0.66582117 0.67617658 0.67784343 0.65638983\n",
      " 0.67320677 0.66444058 0.66259224 0.66192144 0.66535999 0.67238059\n",
      " 0.66640494 0.6729527  0.67374411 0.67579585 0.67917564 0.67781169\n",
      " 0.67987283 0.68387279 0.67933737 0.68043585 0.67468476 0.68995437\n",
      " 0.68248349 0.68781708 0.69054029 0.69129104 0.67538956 0.68367899\n",
      " 0.68917925 0.68506665 0.69128597 0.6895609  0.69831155 0.69001827\n",
      " 0.68932547 0.69540769 0.6936592  0.70432323 0.69810771 0.70348842]\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for c in range(0, nCluster):\n",
    "    print(c)\n",
    "    print(randomForestTestConfM[c])\n",
    "    print(randomForestTestF1[c])\n",
    "    print(randomForestResultSmote[c].cv_results_[\"mean_test_score\"])\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression with SMOTE, change values, RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lrResultSmote=[]\n",
    "lrTestConfM = []\n",
    "lrTestF1 = []\n",
    "for c in range(0, nCluster):\n",
    "    cRatiosMask = np.load(\"cRatiosRFEMaskC\"+str(c)+\".npy\")\n",
    "    cRatiosCluster = cRatios[cRatios.columns[cRatiosMask]]\n",
    "    trainX, testX, trainY, testY = train_test_split(cRatiosCluster, targetLabels == c, test_size=0.2, random_state=42)\n",
    "    sm = SMOTE(random_state=42)\n",
    "    x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "    parameters = {'penalty':('l1', 'l2', 'none'), 'C':[0.1, 0.5, 1, 2, 3]}\n",
    "    lr = LogisticRegression(solver = 'saga', max_iter=500)\n",
    "    lrGridSearch = gscv(lr, parameters, scoring='f1', n_jobs=-1, verbose=4)\n",
    "    lrGridSearch.fit(x_res, y_res)\n",
    "    lrResultSmote.append(lrGridSearch)\n",
    "    lrTestConfM.append(metrics.confusion_matrix(testY, lrGridSearch.best_estimator_.predict(testX)))\n",
    "    lrTestF1.append(metrics.f1_score(testY, lrGridSearch.best_estimator_.predict(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[1134 1430]\n",
      " [  90  120]]\n",
      "0.13636363636363638\n",
      "[0.51938958 0.51931954 0.51934518 0.51932066 0.51929948 0.51941307\n",
      " 0.5193689  0.51920635 0.51927617 0.51929614 0.5193454  0.51927626\n",
      " 0.51941347 0.5193649  0.51918345]\n",
      "--------------\n",
      "1\n",
      "[[1566  918]\n",
      " [ 174  116]]\n",
      "0.17522658610271905\n",
      "[0.46294123 0.46270633 0.46274017 0.46267927 0.46257057 0.4625302\n",
      " 0.46282346 0.46253963 0.46255747 0.46273796 0.46264343 0.46268361\n",
      " 0.46257057 0.46256314 0.46276637]\n",
      "--------------\n",
      "2\n",
      "[[1088 1450]\n",
      " [  85  151]]\n",
      "0.16439847577572128\n",
      "[0.59413335 0.59418741 0.59418837 0.5942246  0.59406336 0.59434602\n",
      " 0.5942759  0.59422415 0.59431202 0.59432073 0.59416107 0.59428491\n",
      " 0.59423359 0.59421442 0.59432175]\n",
      "--------------\n",
      "3\n",
      "[[1403 1012]\n",
      " [ 204  155]]\n",
      "0.20314547837483618\n",
      "[0.49060667 0.48991826 0.49034174 0.4902227  0.49037755 0.49037968\n",
      " 0.49014841 0.49057662 0.49008967 0.49028514 0.49021667 0.48999097\n",
      " 0.49055977 0.49029666 0.4901454 ]\n",
      "--------------\n",
      "4\n",
      "[[1276  975]\n",
      " [ 230  293]]\n",
      "0.3271915131211614\n",
      "[0.56171792 0.56134263 0.56129542 0.56161226 0.56139827 0.56105811\n",
      " 0.56147971 0.56167034 0.56139329 0.56110696 0.5615084  0.56125691\n",
      " 0.56149003 0.56145473 0.5616249 ]\n",
      "--------------\n",
      "5\n",
      "[[1323 1198]\n",
      " [ 140  113]]\n",
      "0.1445012787723785\n",
      "[0.51601999 0.51568051 0.5158817  0.51561608 0.51559657 0.51567359\n",
      " 0.51577287 0.51561851 0.51557816 0.51591818 0.51572653 0.51576406\n",
      " 0.51567454 0.51574874 0.51585186]\n",
      "--------------\n",
      "6\n",
      "[[1678  862]\n",
      " [ 119  115]]\n",
      "0.189925681255161\n",
      "[0.5208955  0.52100006 0.52078815 0.52078769 0.52097678 0.52081587\n",
      " 0.52078764 0.52086894 0.52086782 0.52062786 0.52073808 0.52084063\n",
      " 0.5207637  0.52097585 0.52097281]\n",
      "--------------\n",
      "7\n",
      "[[1163  942]\n",
      " [ 361  308]]\n",
      "0.32100052110474203\n",
      "[0.49696853 0.49706542 0.49708249 0.49666765 0.49697126 0.49665803\n",
      " 0.4968509  0.49719339 0.49684    0.497348   0.49712796 0.49683997\n",
      " 0.49692104 0.49716368 0.49667216]\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for c in range(0, nCluster):\n",
    "    print(c)\n",
    "    print(lrTestConfM[c])\n",
    "    print(lrTestF1[c])\n",
    "    print(lrResultSmote[c].cv_results_[\"mean_test_score\"])\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "svmResultSmote=[]\n",
    "svmTestConfM = []\n",
    "svmTestF1 = []\n",
    "for c in range(0, nCluster):\n",
    "    cRatiosMask = np.load(\"cRatiosRFEMaskC\"+str(c)+\".npy\")\n",
    "    cRatiosCluster = cRatios[cRatios.columns[cRatiosMask]]\n",
    "    pca = PCA(n_components=3, svd_solver='full')\n",
    "    cRatiosCluster = pca.fit_transform(cRatiosCluster)\n",
    "    trainX, testX, trainY, testY = train_test_split(cRatiosCluster, targetLabels == c, test_size=0.2, random_state=42)\n",
    "    sm = SMOTE(random_state=42)\n",
    "    x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "    parameters = {'C':[0.001, 0.01, 1, 2, 5, 10]}\n",
    "    svm = SVC()\n",
    "    svmGridSearch = gscv(svm, parameters, scoring='f1', n_jobs=-1, verbose=4)\n",
    "    svmGridSearch.fit(x_res, y_res)\n",
    "    svmResultSmote.append(svmGridSearch)\n",
    "    svmTestConfM.append(metrics.confusion_matrix(testY, svmGridSearch.best_estimator_.predict(testX)))\n",
    "    svmTestF1.append(metrics.f1_score(testY, svmGridSearch.best_estimator_.predict(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[2561    3]\n",
      " [ 210    0]]\n",
      "0.0\n",
      "[0.26671016 0.26671016 0.26671016 0.13618258]\n",
      "--------------\n",
      "1\n",
      "[[2483    1]\n",
      " [ 290    0]]\n",
      "0.0\n",
      "[0.26702199 0.26702199 0.0017987  0.0017987 ]\n",
      "--------------\n",
      "2\n",
      "[[2538    0]\n",
      " [ 236    0]]\n",
      "0.0\n",
      "[0.2677961  0.00449792 0.00449792 0.00430289]\n",
      "--------------\n",
      "3\n",
      "[[2408    7]\n",
      " [ 358    1]]\n",
      "0.005449591280653951\n",
      "[0.13578174 0.01820837 0.0116607  0.013054  ]\n",
      "--------------\n",
      "4\n",
      "[[   3 2248]\n",
      " [   0  523]]\n",
      "0.3175470552519733\n",
      "[0.53321016 0.53321016 0.66654349 0.66659277]\n",
      "--------------\n",
      "5\n",
      "[[2518    3]\n",
      " [ 252    1]]\n",
      "0.007782101167315175\n",
      "[0.13450329 0.13450329 0.00238233 0.00376817]\n",
      "--------------\n",
      "6\n",
      "[[ 151 2389]\n",
      " [  12  222]]\n",
      "0.15606326889279437\n",
      "[0.28493695 0.33719298 0.65752954 0.56012315]\n",
      "--------------\n",
      "7\n",
      "[[2086   19]\n",
      " [ 663    6]]\n",
      "0.017291066282420747\n",
      "[0.26942591 0.26945226 0.01542229 0.01258602]\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for c in range(0, nCluster):\n",
    "    print(c)\n",
    "    print(svmTestConfM[c])\n",
    "    print(svmTestF1[c])\n",
    "    print(svmResultSmote[c].cv_results_[\"mean_test_score\"])\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lrResultSMOTE.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gradientResultSmote, \"gradientResultSMOTE.pkl\")\n",
    "joblib.dump(randomForestResultSmote, \"randomForestResultSMOTE.pkl\")\n",
    "joblib.dump(lrResultSmote, \"lrResultSMOTE.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lrResultSMOTE.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lrResultSmote, \"lrResultSMOTE.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting with SMOTE nominal values RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    }
   ],
   "source": [
    "gradientResultSmoteN=[]\n",
    "gradientTestConfMN = []\n",
    "gradientTestF1N = []\n",
    "for c in range(0, nCluster):\n",
    "    ratiosMask = np.load(\"ratiosRFEMaskC\"+str(c)+\".npy\")\n",
    "    ratiosCluster = ratios[ratios.columns[ratiosMask]]\n",
    "    trainX, testX, trainY, testY = train_test_split(ratiosCluster, targetLabels == c, test_size=0.2, random_state=42)\n",
    "    sm = SMOTE(random_state=42)\n",
    "    x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "    parameters = {'n_estimators':[1, 2, 3, 4, 5, 6], 'max_depth':[1, 2, 3, 4, 5, 6], 'min_samples_split':[150, 250, 350, 450]}\n",
    "    gbc = GradientBoostingClassifier()\n",
    "    gradientGridSearch = gscv(gbc, parameters, scoring='f1', n_jobs=-1, verbose=4)\n",
    "    gradientGridSearch.fit(x_res, y_res)\n",
    "    gradientResultSmoteN.append(gradientGridSearch)\n",
    "    gradientTestConfMN.append(metrics.confusion_matrix(testY, gradientGridSearch.best_estimator_.predict(testX)))\n",
    "    gradientTestF1N.append(metrics.f1_score(testY, gradientGridSearch.best_estimator_.predict(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[1949  615]\n",
      " [ 110  100]]\n",
      "0.21621621621621623\n",
      "[0.60086615 0.57987545 0.59652532 0.59328446 0.58474724 0.59158788\n",
      " 0.60086615 0.57987545 0.59652532 0.59328446 0.58474724 0.59158788\n",
      " 0.60086615 0.57987545 0.59652532 0.59328446 0.58474724 0.59158788\n",
      " 0.60086615 0.57987545 0.59652532 0.59328446 0.58474724 0.59158788\n",
      " 0.58522846 0.58777211 0.67706787 0.69306847 0.69100355 0.69834955\n",
      " 0.58522846 0.58777211 0.67706787 0.69306847 0.69100355 0.69834955\n",
      " 0.58522846 0.58777211 0.67706787 0.69306847 0.69100355 0.69834955\n",
      " 0.58522846 0.58777211 0.67706787 0.69306847 0.69100355 0.69834955\n",
      " 0.70304153 0.71405272 0.71088067 0.73274357 0.73676152 0.75004494\n",
      " 0.70304153 0.71405272 0.71084863 0.73236174 0.73651452 0.75000841\n",
      " 0.70304153 0.71405272 0.71084863 0.73237636 0.73631525 0.74992536\n",
      " 0.70304153 0.71405272 0.71084863 0.73237636 0.73631525 0.74992536\n",
      " 0.71993481 0.7259554  0.74959434 0.75772337 0.76439725 0.77355834\n",
      " 0.71993481 0.7259554  0.74983337 0.75765713 0.76457039 0.77410019\n",
      " 0.71993481 0.7259554  0.74971754 0.75749939 0.76419377 0.7736217\n",
      " 0.71993481 0.72593576 0.74965291 0.75724655 0.76449697 0.77180102\n",
      " 0.71858999 0.75266158 0.76257583 0.77188256 0.77941908 0.78540463\n",
      " 0.71795548 0.75303596 0.76220522 0.77069141 0.77828147 0.78326271\n",
      " 0.71667485 0.75284054 0.76177721 0.76989431 0.77690638 0.78245009\n",
      " 0.71593706 0.75096876 0.75976451 0.76836836 0.77525623 0.7822186\n",
      " 0.75149543 0.76701    0.78162816 0.7852804  0.79430894 0.8011011\n",
      " 0.74822401 0.76512159 0.7779725  0.78286569 0.79051287 0.79744534\n",
      " 0.74605665 0.76168138 0.7695717  0.78048352 0.78809238 0.79218573\n",
      " 0.74543991 0.75979447 0.76823596 0.77692463 0.78527619 0.78885292]\n",
      "--------------\n",
      "1\n",
      "[[1849  635]\n",
      " [ 211   79]]\n",
      "0.15737051792828685\n",
      "[0.65168898 0.64768462 0.65143733 0.65378593 0.66051492 0.66633444\n",
      " 0.65168898 0.64768462 0.65143733 0.65378593 0.66051492 0.66633444\n",
      " 0.65168898 0.64768462 0.65143733 0.65378593 0.66051492 0.66633444\n",
      " 0.65168898 0.64768462 0.65143733 0.65378593 0.66051492 0.66633444\n",
      " 0.65617964 0.65617964 0.67236791 0.66982258 0.67546769 0.68599754\n",
      " 0.65617964 0.65617964 0.67236791 0.66982258 0.67546769 0.68599754\n",
      " 0.65617964 0.65617964 0.67236791 0.66982258 0.67546769 0.68599754\n",
      " 0.65617964 0.65617964 0.67236791 0.66982258 0.67546769 0.68599754\n",
      " 0.68351065 0.68589236 0.68467144 0.69255556 0.69293296 0.69669751\n",
      " 0.68351065 0.68589236 0.68467144 0.69255556 0.69293296 0.69669751\n",
      " 0.68351065 0.68589236 0.68467144 0.69255556 0.69293296 0.69669751\n",
      " 0.68351065 0.68589236 0.68467144 0.69255556 0.69293296 0.69669751\n",
      " 0.69699425 0.70046669 0.70010581 0.70586834 0.70462429 0.70939295\n",
      " 0.69702681 0.70063545 0.70018848 0.70642134 0.70447708 0.70980042\n",
      " 0.69688996 0.70052085 0.70034636 0.70614454 0.70395332 0.70901801\n",
      " 0.69609644 0.69976475 0.69698936 0.70303781 0.70316462 0.7082099\n",
      " 0.70120624 0.70677044 0.71230891 0.71936819 0.7252484  0.73214197\n",
      " 0.70021509 0.7061571  0.71309325 0.71905702 0.72489591 0.73133414\n",
      " 0.69934044 0.70494487 0.71210225 0.71805302 0.72345526 0.73018596\n",
      " 0.69848327 0.70350425 0.7078241  0.71702656 0.72292792 0.73156818\n",
      " 0.71412539 0.72476056 0.73086156 0.73649073 0.74310152 0.75024769\n",
      " 0.71087974 0.72114969 0.72842212 0.73458572 0.73799317 0.74625488\n",
      " 0.70456694 0.7163757  0.7234585  0.72992099 0.73288603 0.74083335\n",
      " 0.70350261 0.71193996 0.72109988 0.72833716 0.73216485 0.73779398]\n",
      "--------------\n",
      "2\n",
      "[[2046  492]\n",
      " [ 106  130]]\n",
      "0.303030303030303\n",
      "[0.69163964 0.69597419 0.69847544 0.69568536 0.6984666  0.70154673\n",
      " 0.69163964 0.69597419 0.69847544 0.69568536 0.6984666  0.70154673\n",
      " 0.69163964 0.69597419 0.69847544 0.69568536 0.6984666  0.70154673\n",
      " 0.69163964 0.69597419 0.69847544 0.69568536 0.6984666  0.70154673\n",
      " 0.70407673 0.70405908 0.70432528 0.70686235 0.71263149 0.71957952\n",
      " 0.70407673 0.70405908 0.70432528 0.70686235 0.71263149 0.71957952\n",
      " 0.70407673 0.70405908 0.70432528 0.70686235 0.71263149 0.71957952\n",
      " 0.70407673 0.70405908 0.70432528 0.70686235 0.71263149 0.71957952\n",
      " 0.71990575 0.72289016 0.73383068 0.73508216 0.75115788 0.75564043\n",
      " 0.72038642 0.72728293 0.73422218 0.73564629 0.75165099 0.75608766\n",
      " 0.72038642 0.72728293 0.73422218 0.73564629 0.75165099 0.75608766\n",
      " 0.72038642 0.72728293 0.73422218 0.73564629 0.75165099 0.75608766\n",
      " 0.69628811 0.74285772 0.75242468 0.76345166 0.76734106 0.76967745\n",
      " 0.69659824 0.74256726 0.75271973 0.76383506 0.76726595 0.76960835\n",
      " 0.69659824 0.74549574 0.75267737 0.76366231 0.76684709 0.77035264\n",
      " 0.69659824 0.74602538 0.75283086 0.76358524 0.7665564  0.77022018\n",
      " 0.74446792 0.76272131 0.77162885 0.78115314 0.78907335 0.79253404\n",
      " 0.74460524 0.76083401 0.77148637 0.78212877 0.79035284 0.79187276\n",
      " 0.74460524 0.76064861 0.77027948 0.78041918 0.78819378 0.79109397\n",
      " 0.74375592 0.76136931 0.77056387 0.78107325 0.78920037 0.79175941\n",
      " 0.7692556  0.77815469 0.78612833 0.79539443 0.80085103 0.80742067\n",
      " 0.76920175 0.77601841 0.78460258 0.78920602 0.79687036 0.80413926\n",
      " 0.76870782 0.77656944 0.78200772 0.78644391 0.79778808 0.80192022\n",
      " 0.76741652 0.77640174 0.7804863  0.78528758 0.79407489 0.7981601 ]\n",
      "--------------\n",
      "3\n",
      "[[1756  659]\n",
      " [ 217  142]]\n",
      "0.24482758620689657\n",
      "[0.68924668 0.67783881 0.66159475 0.69113854 0.70265007 0.69388176\n",
      " 0.68924668 0.67783881 0.66159475 0.69113854 0.70265007 0.69388176\n",
      " 0.68924668 0.67783881 0.66159475 0.69113854 0.70265007 0.69388176\n",
      " 0.68924668 0.67783881 0.66159475 0.69113854 0.70265007 0.69388176\n",
      " 0.67794479 0.6744048  0.68706509 0.69723138 0.7027587  0.69755467\n",
      " 0.67794479 0.6744048  0.68706509 0.69723138 0.7027587  0.69755467\n",
      " 0.67794479 0.6744048  0.68706509 0.69723138 0.7027587  0.69755467\n",
      " 0.67794479 0.6744048  0.68706509 0.69723138 0.7027587  0.69755467\n",
      " 0.64235632 0.66719538 0.70036894 0.70759413 0.71531564 0.71534663\n",
      " 0.64235632 0.66719538 0.70036894 0.70759413 0.71531564 0.71534663\n",
      " 0.64235632 0.66719538 0.70036894 0.70727731 0.71494062 0.71534663\n",
      " 0.64235632 0.66719538 0.70036894 0.70727731 0.71494062 0.71534663\n",
      " 0.68488457 0.6912805  0.71236641 0.72392823 0.72880735 0.73309131\n",
      " 0.68396578 0.69056212 0.71220323 0.7241896  0.72874965 0.73303873\n",
      " 0.68401893 0.69050668 0.71201098 0.72317305 0.72794905 0.72977077\n",
      " 0.6837072  0.69028517 0.71144249 0.72227728 0.72701465 0.72895984\n",
      " 0.69980908 0.71663388 0.72736848 0.73815608 0.74151127 0.74682577\n",
      " 0.69739308 0.71503141 0.72892107 0.73704513 0.74156733 0.74678146\n",
      " 0.69748507 0.71459871 0.72812969 0.73533993 0.740187   0.74484864\n",
      " 0.69707477 0.71410826 0.7277544  0.73417162 0.73937278 0.74347351\n",
      " 0.711692   0.73152102 0.7294514  0.73794314 0.75054667 0.75701475\n",
      " 0.70950645 0.72754988 0.72957863 0.73618693 0.74762432 0.7536737\n",
      " 0.70836608 0.72800155 0.72563497 0.73448849 0.74695838 0.7524037\n",
      " 0.70762185 0.72613959 0.72428879 0.73318708 0.74665266 0.74997886]\n",
      "--------------\n",
      "4\n",
      "[[1595  656]\n",
      " [ 232  291]]\n",
      "0.39591836734693875\n",
      "[0.67887538 0.60645858 0.61748912 0.61707868 0.61651194 0.63556145\n",
      " 0.67887538 0.60645858 0.61748912 0.61707868 0.61651194 0.63556145\n",
      " 0.67887538 0.60645858 0.61748912 0.61707868 0.61651194 0.63556145\n",
      " 0.67887538 0.60645858 0.61748912 0.61707868 0.61651194 0.63556145\n",
      " 0.62443066 0.66265214 0.67877818 0.66611203 0.65254834 0.66975687\n",
      " 0.62443066 0.66265214 0.67877818 0.66611203 0.65254834 0.66975687\n",
      " 0.62443066 0.66265214 0.67877818 0.66611203 0.65254834 0.66975687\n",
      " 0.62443066 0.66265214 0.67877818 0.66611203 0.65254834 0.66975687\n",
      " 0.65514311 0.67531199 0.68983383 0.67944064 0.68678735 0.69285021\n",
      " 0.65514311 0.67531199 0.68983383 0.67944064 0.68678735 0.69285021\n",
      " 0.65514311 0.67531199 0.68983383 0.67944064 0.68678735 0.69277667\n",
      " 0.65514311 0.67531199 0.68983383 0.67944064 0.68678735 0.69277667\n",
      " 0.67504661 0.67593522 0.69068208 0.70404752 0.71132298 0.71288756\n",
      " 0.67504661 0.67593522 0.69068208 0.70404752 0.71137705 0.71248091\n",
      " 0.67504661 0.67593522 0.69072009 0.70377189 0.71114067 0.71219651\n",
      " 0.67504661 0.67593522 0.69072009 0.70364293 0.71082968 0.71188001\n",
      " 0.68746239 0.70111222 0.71185515 0.71693773 0.72308549 0.73114483\n",
      " 0.68598879 0.69947222 0.70941367 0.71380041 0.71836563 0.72584306\n",
      " 0.68598879 0.69901193 0.70867585 0.71199003 0.71754209 0.72644634\n",
      " 0.67715969 0.69697078 0.70502426 0.70974903 0.7145288  0.72562244\n",
      " 0.70024273 0.71375367 0.72149176 0.72797128 0.73061861 0.73487482\n",
      " 0.69516457 0.71039262 0.7148757  0.72492275 0.72672247 0.73103993\n",
      " 0.69587285 0.71000954 0.71605155 0.72356299 0.72350008 0.7261748\n",
      " 0.68589071 0.70710919 0.71329031 0.72139097 0.7209677  0.7274459 ]\n",
      "--------------\n",
      "5\n",
      "[[1860  661]\n",
      " [ 151  102]]\n",
      "0.20078740157480313\n",
      "[0.68468888 0.67871547 0.67871547 0.68078786 0.68563097 0.68399021\n",
      " 0.68468888 0.67871547 0.67871547 0.68078786 0.68563097 0.68399021\n",
      " 0.68468888 0.67871547 0.67871547 0.68078786 0.68563097 0.68399021\n",
      " 0.68468888 0.67871547 0.67871547 0.68078786 0.68563097 0.68399021\n",
      " 0.66727917 0.69086359 0.68261463 0.68823609 0.68762604 0.69683423\n",
      " 0.66727917 0.69086359 0.68261463 0.68823609 0.68762604 0.69683423\n",
      " 0.66727917 0.69086359 0.68261463 0.68823609 0.68762604 0.69683423\n",
      " 0.66727917 0.69086359 0.68261463 0.68823609 0.68762604 0.69683423\n",
      " 0.66567454 0.67922332 0.69293844 0.69583372 0.70819326 0.7144303\n",
      " 0.66567454 0.67922332 0.69293844 0.69583372 0.70819326 0.7144303\n",
      " 0.66567454 0.67922332 0.69293844 0.69583372 0.70819326 0.7144303\n",
      " 0.66567454 0.67922332 0.69293844 0.69583372 0.70819326 0.7144303\n",
      " 0.69820768 0.70180152 0.70896467 0.71723159 0.72443371 0.73094332\n",
      " 0.69820768 0.70180152 0.70896467 0.71713934 0.72423596 0.73055698\n",
      " 0.69820768 0.70180152 0.70896467 0.71694695 0.72420116 0.73029207\n",
      " 0.69823894 0.70180152 0.70884196 0.71704656 0.72386929 0.72979827\n",
      " 0.69203711 0.71422633 0.71918866 0.72734406 0.73898557 0.74443091\n",
      " 0.69210388 0.71377896 0.71893647 0.72616258 0.73706253 0.74323821\n",
      " 0.69084108 0.71158008 0.72104415 0.72531993 0.73543859 0.74330808\n",
      " 0.69084108 0.71133941 0.7198646  0.72550046 0.73470627 0.74270239\n",
      " 0.70876685 0.72951161 0.74105695 0.75108994 0.75761309 0.76368585\n",
      " 0.70370217 0.72463768 0.74008521 0.74653807 0.75395287 0.76012238\n",
      " 0.70297491 0.72323593 0.73716668 0.74327923 0.75014109 0.75581442\n",
      " 0.70182005 0.72291444 0.73306554 0.73941137 0.74587801 0.75216107]\n",
      "--------------\n",
      "6\n",
      "[[1915  625]\n",
      " [ 129  105]]\n",
      "0.21784232365145229\n",
      "[0.62933889 0.61697808 0.63731321 0.6305032  0.64322118 0.6509342\n",
      " 0.62933889 0.61697808 0.63731321 0.6305032  0.64322118 0.6509342\n",
      " 0.62933889 0.61697808 0.63731321 0.6305032  0.64322118 0.6509342\n",
      " 0.62933889 0.61697808 0.63731321 0.6305032  0.64322118 0.6509342\n",
      " 0.62101121 0.63080904 0.68991174 0.69760241 0.69343972 0.69881465\n",
      " 0.62101121 0.63080904 0.68991174 0.69760241 0.69343972 0.69881465\n",
      " 0.62101121 0.63080904 0.68991174 0.69760241 0.69343972 0.69881465\n",
      " 0.62101121 0.63080904 0.68991174 0.69760241 0.69343972 0.69881465\n",
      " 0.69837131 0.68860647 0.69863376 0.71506657 0.72633043 0.72730446\n",
      " 0.69837131 0.68860647 0.69863376 0.71506657 0.72633043 0.72730446\n",
      " 0.69837131 0.68860647 0.69863376 0.71506657 0.72633043 0.72730446\n",
      " 0.69837131 0.68860647 0.69863376 0.71506657 0.72633043 0.72730446\n",
      " 0.7052276  0.70724754 0.72028353 0.73138477 0.74471698 0.75073082\n",
      " 0.7052276  0.70774689 0.7197517  0.73066348 0.74391806 0.75105391\n",
      " 0.70536835 0.7071924  0.7198614  0.73091005 0.74334772 0.75158552\n",
      " 0.7013291  0.70495914 0.72040328 0.73076209 0.74329077 0.75023973\n",
      " 0.71414747 0.73154759 0.74050389 0.75111889 0.75710651 0.76633291\n",
      " 0.71478572 0.7321126  0.7383313  0.7528161  0.75612133 0.76611363\n",
      " 0.71262679 0.73028349 0.736833   0.75224063 0.75618071 0.76359726\n",
      " 0.7078339  0.72506918 0.73646118 0.74949493 0.75435313 0.76345443\n",
      " 0.73949918 0.74700869 0.76058779 0.76970834 0.77531607 0.78205079\n",
      " 0.73635449 0.74466316 0.75912781 0.76701177 0.77283736 0.78052804\n",
      " 0.73247301 0.73993522 0.75605741 0.76602052 0.7710884  0.77597038\n",
      " 0.72567616 0.73577748 0.75278597 0.7603558  0.7714667  0.77430418]\n",
      "--------------\n",
      "7\n",
      "[[1408  697]\n",
      " [ 272  397]]\n",
      "0.450368689733409\n",
      "[0.66624022 0.61065835 0.64661815 0.65361075 0.65032355 0.65897701\n",
      " 0.66624022 0.61065835 0.64661815 0.65361075 0.65032355 0.65897701\n",
      " 0.66624022 0.61065835 0.64661815 0.65361075 0.65032355 0.65897701\n",
      " 0.66624022 0.61065835 0.64661815 0.65361075 0.65032355 0.65897701\n",
      " 0.61965018 0.66252812 0.66396868 0.66832128 0.65963352 0.66327492\n",
      " 0.61965018 0.66252812 0.66396868 0.66832128 0.65963352 0.66327492\n",
      " 0.61965018 0.66252812 0.66396868 0.66832128 0.65963352 0.66327492\n",
      " 0.61965018 0.66252812 0.66396868 0.66832128 0.65963352 0.66327492\n",
      " 0.65882945 0.65219941 0.67239102 0.67177819 0.67821802 0.68008937\n",
      " 0.65882945 0.65219941 0.67239102 0.67177819 0.67821802 0.68008937\n",
      " 0.65882945 0.65219941 0.67239102 0.67177819 0.67821802 0.68008937\n",
      " 0.65882945 0.65219941 0.67239102 0.67177819 0.67821802 0.68008937\n",
      " 0.65973727 0.67978173 0.68469693 0.6863152  0.69111554 0.69727783\n",
      " 0.65973727 0.67936815 0.68403146 0.6860397  0.68977378 0.69608664\n",
      " 0.65965502 0.67915525 0.68341272 0.68551283 0.68653535 0.69492289\n",
      " 0.65965502 0.68024054 0.68332348 0.68523689 0.68789971 0.69310768\n",
      " 0.67249485 0.68464928 0.7012436  0.70195964 0.70499807 0.71206698\n",
      " 0.67132549 0.68292937 0.6993711  0.70038236 0.70250291 0.70719782\n",
      " 0.67052294 0.68064517 0.6949312  0.69890293 0.70059353 0.7050445\n",
      " 0.66348375 0.6806084  0.69422232 0.69746897 0.70254605 0.70472482\n",
      " 0.68269539 0.6966043  0.70635745 0.71735758 0.71875669 0.72465401\n",
      " 0.67985266 0.69617369 0.71038089 0.71011252 0.71793006 0.72028542\n",
      " 0.6770444  0.69431352 0.70340978 0.70671964 0.71131989 0.71682107\n",
      " 0.6665179  0.68886608 0.69926312 0.70678387 0.70896635 0.71244789]\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for c in range(0, nCluster):\n",
    "    print(c)\n",
    "    print(gradientTestConfMN[c])\n",
    "    print(gradientTestF1N[c])\n",
    "    print(gradientResultSmoteN[c].cv_results_[\"mean_test_score\"])\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest with SMOTE nominal values RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n",
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n",
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n",
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n",
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n",
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n",
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n",
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n"
     ]
    }
   ],
   "source": [
    "randomForestResultSmoteN=[]\n",
    "randomForestTestConfMN = []\n",
    "randomForestTestF1N = []\n",
    "for c in range(0, nCluster):\n",
    "    ratiosMask = np.load(\"ratiosRFEMaskC\"+str(c)+\".npy\")\n",
    "    ratiosCluster = ratios[ratios.columns[ratiosMask]]\n",
    "    trainX, testX, trainY, testY = train_test_split(ratiosCluster, targetLabels == c, test_size=0.2, random_state=42)\n",
    "    sm = SMOTE(random_state=42)\n",
    "    x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "    parameters = {'n_estimators':[2, 3, 4, 5, 6, 7, 8, 9, 10], 'max_depth':[1, 2, 3, 4, 5, 6, 7]}\n",
    "    rfc = RandomForestClassifier()\n",
    "    randomForestSearch = gscv(rfc, parameters, scoring='f1', n_jobs=-1, verbose=4)\n",
    "    randomForestSearch.fit(x_res, y_res)\n",
    "    randomForestResultSmoteN.append(randomForestSearch)\n",
    "    randomForestTestConfMN.append(metrics.confusion_matrix(testY, randomForestSearch.best_estimator_.predict(testX)))\n",
    "    randomForestTestF1N.append(metrics.f1_score(testY, randomForestSearch.best_estimator_.predict(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[2017  547]\n",
      " [ 122   88]]\n",
      "0.20828402366863907\n",
      "[0.62221281 0.64679692 0.65163253 0.66554633 0.6435418  0.69806133\n",
      " 0.69523313 0.70053024 0.70947172 0.68949591 0.70510304 0.70479229\n",
      " 0.7172315  0.70700978 0.70094348 0.70785688 0.70326312 0.72202476\n",
      " 0.68564606 0.70170341 0.71647257 0.7275335  0.72519    0.73629132\n",
      " 0.75826677 0.75299981 0.74344118 0.71650814 0.73090658 0.73851179\n",
      " 0.74478394 0.7481521  0.74761253 0.75207246 0.75895987 0.76559688\n",
      " 0.71448265 0.7526313  0.75044301 0.76200676 0.76322509 0.77454573\n",
      " 0.77430827 0.78165699 0.77757959 0.73484811 0.76135255 0.77199617\n",
      " 0.78154745 0.78924723 0.78223174 0.79043076 0.79190864 0.79454824\n",
      " 0.76762152 0.77386962 0.79040093 0.79973214 0.79642099 0.80524406\n",
      " 0.8117708  0.81289076 0.81317918]\n",
      "--------------\n",
      "1\n",
      "[[1902  582]\n",
      " [ 207   83]]\n",
      "0.1738219895287958\n",
      "[0.57370445 0.64135982 0.66922731 0.65352805 0.66218633 0.67807556\n",
      " 0.68115275 0.67423402 0.66792619 0.6748816  0.66189295 0.66626469\n",
      " 0.66655769 0.68087622 0.67856227 0.69215589 0.67581879 0.69302598\n",
      " 0.67489508 0.69002649 0.69415586 0.69179949 0.69201191 0.69525332\n",
      " 0.68702101 0.69048707 0.698551   0.67767057 0.69241414 0.6981211\n",
      " 0.69492765 0.69518261 0.70569342 0.70627711 0.70882521 0.69819945\n",
      " 0.69589232 0.70484211 0.71048232 0.7163444  0.71599051 0.7161981\n",
      " 0.71679317 0.71968359 0.72205268 0.70245287 0.7173592  0.7272436\n",
      " 0.73098063 0.73116335 0.73686886 0.7366095  0.73500329 0.73438376\n",
      " 0.71376335 0.73000082 0.734272   0.74173384 0.74741016 0.75565705\n",
      " 0.75583899 0.75283927 0.7543516 ]\n",
      "--------------\n",
      "2\n",
      "[[2015  523]\n",
      " [ 118  118]]\n",
      "0.26909920182440134\n",
      "[0.68841008 0.65227614 0.64343613 0.68635924 0.69736604 0.71521048\n",
      " 0.69492331 0.69393954 0.71246138 0.69259524 0.70174994 0.70998889\n",
      " 0.71942044 0.71281598 0.71493847 0.72822369 0.71222227 0.71874708\n",
      " 0.71364915 0.72747375 0.72528791 0.73871012 0.7322398  0.74199708\n",
      " 0.74244402 0.74645679 0.74744872 0.74042886 0.74649923 0.74721048\n",
      " 0.75506483 0.75518216 0.7566741  0.76275278 0.76142468 0.77160575\n",
      " 0.73773134 0.76400994 0.76229971 0.77776054 0.7766975  0.76944221\n",
      " 0.77642545 0.78023413 0.78681904 0.76241765 0.77513325 0.78534585\n",
      " 0.78456549 0.78988869 0.79330314 0.79531646 0.79667648 0.79794177\n",
      " 0.77569788 0.78874464 0.80195638 0.8046639  0.80771848 0.81043392\n",
      " 0.81207258 0.81342663 0.82075293]\n",
      "--------------\n",
      "3\n",
      "[[1756  659]\n",
      " [ 213  146]]\n",
      "0.2508591065292097\n",
      "[0.62469535 0.63084415 0.65530082 0.65960478 0.68652512 0.67941185\n",
      " 0.68458166 0.6933896  0.69116403 0.63913557 0.67486095 0.68005087\n",
      " 0.68640488 0.70271518 0.70400401 0.70070144 0.69841692 0.69843099\n",
      " 0.66566386 0.67808389 0.70873733 0.70390467 0.70874365 0.70394713\n",
      " 0.70804891 0.71247552 0.71100162 0.70094579 0.69204277 0.70510937\n",
      " 0.71440982 0.72307744 0.72402036 0.71315657 0.72145661 0.72547936\n",
      " 0.69587748 0.71952302 0.72063563 0.724241   0.72825491 0.73169891\n",
      " 0.73263114 0.73271575 0.73125397 0.70573388 0.72582424 0.73490782\n",
      " 0.74107494 0.74907414 0.73962468 0.74639628 0.74893027 0.75056817\n",
      " 0.72050099 0.73786761 0.74823587 0.74462412 0.75781866 0.75857389\n",
      " 0.76452326 0.76118451 0.76693849]\n",
      "--------------\n",
      "4\n",
      "[[1609  642]\n",
      " [ 252  271]]\n",
      "0.3774373259052925\n",
      "[0.6275244  0.63877105 0.63467963 0.65924171 0.65219724 0.668665\n",
      " 0.64637199 0.67211096 0.67019838 0.64281962 0.66139692 0.65703129\n",
      " 0.65926982 0.6571785  0.66495969 0.66919633 0.67366211 0.6710231\n",
      " 0.64972809 0.67198607 0.67379952 0.68371972 0.68459248 0.68483043\n",
      " 0.69574729 0.68011847 0.68864428 0.64942144 0.68313606 0.69301959\n",
      " 0.7063369  0.69069831 0.68955004 0.69403931 0.69921989 0.69743921\n",
      " 0.68876508 0.69018279 0.69322988 0.70344093 0.71402511 0.70876253\n",
      " 0.70295338 0.71059892 0.72139921 0.70213123 0.68691893 0.71106834\n",
      " 0.7191163  0.71339785 0.72170695 0.72786252 0.71483448 0.71830953\n",
      " 0.6997709  0.7118252  0.71941712 0.72251505 0.72441574 0.7292116\n",
      " 0.73418055 0.73402949 0.7361727 ]\n",
      "--------------\n",
      "5\n",
      "[[1912  609]\n",
      " [ 151  102]]\n",
      "0.21161825726141079\n",
      "[0.65535433 0.68140902 0.67181561 0.6449583  0.6820581  0.67443375\n",
      " 0.663826   0.68324198 0.68704954 0.66271308 0.62621565 0.68717435\n",
      " 0.68239032 0.69533907 0.70524517 0.69965842 0.6956373  0.70317791\n",
      " 0.6861951  0.68901765 0.69133106 0.70591445 0.69943623 0.7101054\n",
      " 0.71223111 0.71069663 0.71123853 0.69974813 0.70548151 0.71049332\n",
      " 0.71657185 0.72694561 0.72262908 0.7187546  0.72658136 0.72327773\n",
      " 0.6903095  0.7155729  0.72546501 0.72399565 0.73570038 0.7371103\n",
      " 0.73488522 0.74197665 0.74177517 0.7178475  0.73015588 0.74112824\n",
      " 0.74963371 0.75345723 0.74833314 0.75520445 0.75506151 0.76226136\n",
      " 0.72287287 0.7474924  0.75685739 0.7607683  0.75941915 0.77108204\n",
      " 0.77169631 0.77796824 0.77745909]\n",
      "--------------\n",
      "6\n",
      "[[1933  607]\n",
      " [ 141   93]]\n",
      "0.1991434689507495\n",
      "[0.6323853  0.66478045 0.64100304 0.67911149 0.67494439 0.67035611\n",
      " 0.68307268 0.68544303 0.70026092 0.64488032 0.67855947 0.70902903\n",
      " 0.69057606 0.70518168 0.69097549 0.72004802 0.6974537  0.71695768\n",
      " 0.69799903 0.68977569 0.71554293 0.72203298 0.71722479 0.73428981\n",
      " 0.71874083 0.73023624 0.72745535 0.70025732 0.71796993 0.7262421\n",
      " 0.72806869 0.72998841 0.74026616 0.7451976  0.74331145 0.74651147\n",
      " 0.71590924 0.73316243 0.74968563 0.75093407 0.75326788 0.756732\n",
      " 0.7572384  0.75674687 0.76109382 0.73974269 0.75137765 0.75724655\n",
      " 0.7636353  0.76722829 0.76433755 0.77334478 0.77527525 0.78275641\n",
      " 0.75210053 0.75906247 0.7723707  0.78137944 0.78520676 0.78591784\n",
      " 0.78845494 0.79055394 0.78906148]\n",
      "--------------\n",
      "7\n",
      "[[1412  693]\n",
      " [ 294  375]]\n",
      "0.4317789291882556\n",
      "[0.63143838 0.63036785 0.62718504 0.62188849 0.66791863 0.63850766\n",
      " 0.64237173 0.659522   0.65473457 0.66761679 0.64780984 0.65836641\n",
      " 0.65914933 0.66579456 0.6483467  0.67112405 0.6737103  0.67124411\n",
      " 0.65687607 0.6774981  0.67399448 0.6698526  0.67794945 0.66787611\n",
      " 0.67573654 0.68070125 0.68087827 0.67569133 0.66186474 0.67906367\n",
      " 0.68627568 0.68750356 0.6776533  0.6870482  0.68987512 0.68089883\n",
      " 0.68072832 0.68669348 0.69378491 0.6919428  0.69168186 0.6996754\n",
      " 0.70121523 0.70034451 0.6971982  0.67488793 0.70085464 0.70504703\n",
      " 0.71010986 0.71152908 0.71027916 0.71350588 0.71497842 0.7142971\n",
      " 0.6879684  0.70248424 0.71066597 0.71787679 0.71744685 0.72421502\n",
      " 0.72549901 0.72710459 0.72704171]\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for c in range(0, nCluster):\n",
    "    print(c)\n",
    "    print(randomForestTestConfMN[c])\n",
    "    print(randomForestTestF1N[c])\n",
    "    print(randomForestResultSmoteN[c].cv_results_[\"mean_test_score\"])\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with SMOTE nominal values RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akos\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lrResultSmoteN=[]\n",
    "lrTestConfMN = []\n",
    "lrTestF1N = []\n",
    "for c in range(0, nCluster):\n",
    "    ratiosMask = np.load(\"ratiosRFEMaskC\"+str(c)+\".npy\")\n",
    "    ratiosCluster = ratios[ratios.columns[ratiosMask]]\n",
    "    trainX, testX, trainY, testY = train_test_split(ratiosCluster, targetLabels == c, test_size=0.2, random_state=42)\n",
    "    sm = SMOTE(random_state=42)\n",
    "    x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "    parameters = {'penalty':('l1', 'l2', 'none'), 'C':[0.1, 0.5, 1, 2, 3]}\n",
    "    lr = LogisticRegression(solver = 'saga', max_iter=500)\n",
    "    lrGridSearch = gscv(lr, parameters, scoring='f1', n_jobs=-1, verbose=4)\n",
    "    lrGridSearch.fit(x_res, y_res)\n",
    "    lrResultSmoteN.append(lrGridSearch)\n",
    "    lrTestConfMN.append(metrics.confusion_matrix(testY, lrGridSearch.best_estimator_.predict(testX)))\n",
    "    lrTestF1N.append(metrics.f1_score(testY, lrGridSearch.best_estimator_.predict(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[ 890 1674]\n",
      " [  40  170]]\n",
      "0.1655306718597858\n",
      "[0.67213341 0.67090294 0.67084369 0.671033   0.67066499 0.67074666\n",
      " 0.67095757 0.6708267  0.67087507 0.6709283  0.67087494 0.67071533\n",
      " 0.67084896 0.67071881 0.67076928]\n",
      "--------------\n",
      "1\n",
      "[[1833  651]\n",
      " [ 201   89]]\n",
      "0.17281553398058253\n",
      "[0.39347274 0.38808443 0.3886938  0.38870297 0.38804614 0.38925684\n",
      " 0.38900233 0.38830624 0.38889372 0.38870588 0.38849142 0.38890842\n",
      " 0.38803885 0.38872527 0.38814672]\n",
      "--------------\n",
      "2\n",
      "[[1408 1130]\n",
      " [  77  159]]\n",
      "0.20852459016393443\n",
      "[0.67025908 0.66833192 0.66805529 0.66845913 0.66821138 0.66833125\n",
      " 0.66839494 0.66839451 0.6682671  0.66824771 0.66836341 0.6683641\n",
      " 0.66832918 0.66815256 0.66823491]\n",
      "--------------\n",
      "3\n",
      "[[ 786 1629]\n",
      " [  75  284]]\n",
      "0.25\n",
      "[0.6435327  0.63861932 0.63866109 0.63953204 0.63867452 0.6385625\n",
      " 0.63926528 0.63876333 0.63852899 0.63902028 0.63875419 0.6386702\n",
      " 0.63893721 0.63867676 0.63858951]\n",
      "--------------\n",
      "4\n",
      "[[ 469 1782]\n",
      " [  36  487]]\n",
      "0.3488538681948424\n",
      "[0.68224385 0.68253858 0.68260536 0.68211022 0.68256022 0.68241322\n",
      " 0.68243874 0.68239569 0.68230493 0.68249874 0.68249922 0.6824039\n",
      " 0.68233757 0.68244452 0.68246986]\n",
      "--------------\n",
      "5\n",
      "[[1629  892]\n",
      " [ 103  150]]\n",
      "0.23166023166023167\n",
      "[0.56382202 0.56618011 0.56620334 0.56603728 0.56585972 0.56630587\n",
      " 0.56634216 0.5661691  0.56622778 0.56582192 0.56656576 0.56645388\n",
      " 0.56667552 0.56614389 0.5662332 ]\n",
      "--------------\n",
      "6\n",
      "[[1654  886]\n",
      " [  94  140]]\n",
      "0.22222222222222218\n",
      "[0.60452045 0.60606866 0.60614084 0.6064279  0.60603547 0.60613891\n",
      " 0.60626064 0.60603251 0.60610542 0.60614895 0.60609753 0.60606899\n",
      " 0.60613524 0.60609523 0.60616779]\n",
      "--------------\n",
      "7\n",
      "[[ 741 1364]\n",
      " [ 123  546]]\n",
      "0.42341993020550595\n",
      "[0.67470657 0.67293319 0.67260633 0.67268267 0.67280431 0.67280398\n",
      " 0.67284296 0.67277218 0.67274207 0.67291435 0.67277339 0.67274131\n",
      " 0.67287144 0.67264573 0.67270739]\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for c in range(0, nCluster):\n",
    "    print(c)\n",
    "    print(lrTestConfMN[c])\n",
    "    print(lrTestF1N[c])\n",
    "    print(lrResultSmoteN[c].cv_results_[\"mean_test_score\"])\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with SMOTE nominal values RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "svmResultSmoteN=[]\n",
    "svmTestConfMN = []\n",
    "svmTestF1N = []\n",
    "for c in range(0, nCluster):\n",
    "    ratiosMask = np.load(\"ratiosRFEMaskC\"+str(c)+\".npy\")\n",
    "    ratiosCluster = ratios[ratios.columns[ratiosMask]]\n",
    "    pca = PCA(n_components=3, svd_solver='full')\n",
    "    ratiosCluster = pca.fit_transform(ratiosCluster)\n",
    "    trainX, testX, trainY, testY = train_test_split(ratiosCluster, targetLabels == c, test_size=0.2, random_state=42)\n",
    "    sm = SMOTE(random_state=42)\n",
    "    x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "    parameters = {'C':[0.001, 0.01, 0.1, 0.5, 1, 2, 5, 10]}\n",
    "    svm = SVC()\n",
    "    svmGridSearch = gscv(svm, parameters, scoring='f1', n_jobs=-1, verbose=4)\n",
    "    svmGridSearch.fit(x_res, y_res)\n",
    "    svmResultSmoteN.append(svmGridSearch)\n",
    "    svmTestConfMN.append(metrics.confusion_matrix(testY, svmGridSearch.best_estimator_.predict(testX)))\n",
    "    svmTestF1N.append(metrics.f1_score(testY, svmGridSearch.best_estimator_.predict(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[2559    5]\n",
      " [ 209    1]]\n",
      "0.009259259259259259\n",
      "[0.13878112 0.13878112 0.14045676 0.00900014 0.00996686 0.01112344\n",
      " 0.01284763 0.01457391]\n",
      "--------------\n",
      "1\n",
      "[[  96 2388]\n",
      " [   8  282]]\n",
      "0.19054054054054056\n",
      "[0.39973244 0.39973244 0.40059757 0.14110875 0.24857309 0.13970642\n",
      " 0.55005324 0.65990359]\n",
      "--------------\n",
      "2\n",
      "[[2538    0]\n",
      " [ 236    0]]\n",
      "0.0\n",
      "[0.26992085 0.26992085 0.01591068 0.03758957 0.05508125 0.07557918\n",
      " 0.11107171 0.13424146]\n",
      "--------------\n",
      "3\n",
      "[[2395   20]\n",
      " [ 354    5]]\n",
      "0.026041666666666664\n",
      "[0.15324756 0.03397911 0.04910658 0.06422109 0.06726087 0.07073788\n",
      " 0.07698154 0.08023786]\n",
      "--------------\n",
      "4\n",
      "[[  14 2237]\n",
      " [   2  521]]\n",
      "0.31758610179823227\n",
      "[0.53323465 0.53323465 0.66619732 0.66557651 0.66445563 0.66410406\n",
      " 0.6631545  0.66275056]\n",
      "--------------\n",
      "5\n",
      "[[   6 2515]\n",
      " [   0  253]]\n",
      "0.16749420721615357\n",
      "[0.53360027 0.53360027 0.666624   0.66657909 0.6663557  0.66631065\n",
      " 0.66573146 0.66575047]\n",
      "--------------\n",
      "6\n",
      "[[  41 2499]\n",
      " [   2  232]]\n",
      "0.15649241146711634\n",
      "[0.66451463 0.66451463 0.66436837 0.66236007 0.6610263  0.65767281\n",
      " 0.65368144 0.65235985]\n",
      "--------------\n",
      "7\n",
      "[[  25 2080]\n",
      " [   2  667]]\n",
      "0.3905152224824356\n",
      "[0.40023841 0.40023841 0.40962529 0.66722153 0.66714216 0.66727456\n",
      " 0.66761884 0.6682823 ]\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for c in range(0, nCluster):\n",
    "    print(c)\n",
    "    print(svmTestConfMN[c])\n",
    "    print(svmTestF1N[c])\n",
    "    print(svmResultSmoteN[c].cv_results_[\"mean_test_score\"])\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lrResultCSMOTEN.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gradientResultSmoteN, \"gradientResultSMOTEN.pkl\")\n",
    "joblib.dump(randomForestResultSmoteN, \"randomForestResultCSMOTEN.pkl\")\n",
    "joblib.dump(lrResultSmoteN, \"lrResultCSMOTEN.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lrResultCSMOTEN.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lrResultSmoteN, \"lrResultCSMOTEN.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged clusters GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[[1062  520]\n",
      " [ 335  857]]\n",
      "0.6671856753600623\n"
     ]
    }
   ],
   "source": [
    "ratiosMask = np.load(\"ratiosRFEmask.npy\")\n",
    "ratiosCluster = ratios[ratios.columns[ratiosMask]]\n",
    "trainX, testX, trainY, testY = train_test_split(ratiosCluster, np.logical_or(targetLabels == 4, targetLabels == 7), test_size=0.2, random_state=42)\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "parameters = {'n_estimators':[1, 2, 3, 4, 5, 6], 'max_depth':[1, 2, 3, 4, 5, 6], 'min_samples_split':[150, 250, 350, 450]}\n",
    "gbc = GradientBoostingClassifier()\n",
    "gradientGridSearch = gscv(gbc, parameters, scoring='f1', n_jobs=-1, verbose=4)\n",
    "gradientGridSearch.fit(x_res, y_res)\n",
    "#gradientResultSmoteN.append(gradientGridSearch)\n",
    "print(metrics.confusion_matrix(testY, gradientGridSearch.best_estimator_.predict(testX)))\n",
    "print(metrics.f1_score(testY, gradientGridSearch.best_estimator_.predict(testX)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged clusters RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 616 but corresponding boolean dimension is 623",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-5e770980de40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mratiosMask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ratiosRFEmask.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mratiosCluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratios\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mratios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mratiosMask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratiosCluster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetLabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetLabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4614\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4616\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4617\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4618\u001b[0m             \u001b[1;31m# error: Argument 1 to \"ndim\" has incompatible type \"Union[ExtensionArray,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 616 but corresponding boolean dimension is 623"
     ]
    }
   ],
   "source": [
    "ratiosMask = np.load(\"ratiosRFEmask.npy\")\n",
    "ratiosCluster = ratios[ratios.columns[ratiosMask]]\n",
    "trainX, testX, trainY, testY = train_test_split(ratiosCluster, np.logical_or(targetLabels == 4, targetLabels == 7), test_size=0.2, random_state=42)\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "parameters = {'n_estimators':[1, 2, 3, 4, 5, 6], 'max_depth':[1, 2, 3, 4, 5, 6], 'min_samples_split':[150, 250, 350, 450]}\n",
    "gbc = RandomForestClassifier()\n",
    "gradientGridSearch = gscv(gbc, parameters, scoring='f1', n_jobs=-1, verbose=4)\n",
    "gradientGridSearch.fit(x_res, y_res)\n",
    "#gradientResultSmoteN.append(gradientGridSearch)\n",
    "print(metrics.confusion_matrix(testY, gradientGridSearch.best_estimator_.predict(testX)))\n",
    "print(metrics.f1_score(testY, gradientGridSearch.best_estimator_.predict(testX)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged Clusters LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 685  248]\n",
      " [ 586 1255]]\n",
      "0.7505980861244019\n"
     ]
    }
   ],
   "source": [
    "ratiosMask = np.load(\"ratiosRFEmask.npy\")\n",
    "ratiosCluster = ratios[ratios.columns[ratiosMask]]\n",
    "#ratiosCluster.drop(list(ratiosCluster.filter(like = 'TAH187')), axis = 1, inplace = True)\n",
    "tL = np.logical_or(np.logical_or(targetLabels == 4, targetLabels == 7), np.logical_or(targetLabels == 3, targetLabels == 1))\n",
    "trainX, testX, trainY, testY = train_test_split(ratiosCluster, tL, test_size=0.2, random_state=42)\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_resample(trainX, trainY)\n",
    "gbc = LogisticRegression(C=4.5, random_state = 42, max_iter=5000)\n",
    "gbc.fit(x_res, y_res)\n",
    "#gradientResultSmoteN.append(gradientGridSearch)\n",
    "print(metrics.confusion_matrix(testY, gbc.predict(testX)))\n",
    "print(metrics.f1_score(testY, gbc.predict(testX)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-25c260e171af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "fi = np.argsort(-gbc.feature_importances_)\n",
    "gbc.feature_importances_[fi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.05835381e+00, -3.28982473e+00, -3.18427408e+00,  2.87466942e+00,\n",
       "       -2.21143893e+00,  1.99646980e+00, -1.29438158e+00, -1.09342701e+00,\n",
       "       -8.75601429e-01, -8.70991992e-01,  7.73280712e-01,  6.71774439e-01,\n",
       "       -6.06183672e-01, -5.82536837e-01, -4.80019080e-01,  4.08640679e-01,\n",
       "       -3.74900692e-01, -3.59624223e-01, -3.36258781e-01,  3.23461924e-01,\n",
       "       -2.97159675e-01,  2.62529252e-01, -2.57368284e-01, -2.19676966e-01,\n",
       "        2.19521632e-01,  1.95165114e-01, -1.53298561e-01,  1.30019198e-01,\n",
       "       -1.11709068e-01, -9.68162798e-02,  8.92648269e-02,  8.80363177e-02,\n",
       "        7.84697877e-02, -5.49220487e-02, -5.42833918e-02,  4.98302838e-02,\n",
       "        4.26286571e-02, -3.42930543e-02,  2.96348172e-02,  2.28615241e-02,\n",
       "        2.25060913e-02,  1.29970144e-02,  1.24966016e-02, -1.17135499e-02,\n",
       "        1.13689422e-02,  9.71100347e-03,  7.67243254e-03, -2.30267826e-03,\n",
       "        1.34896485e-03,  7.25110673e-04])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = np.argsort(-abs(w))\n",
    "w[fi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.16008375e+03, 1.77195654e+01, 7.36301722e+00, 2.16686346e+00,\n",
       "       1.95770807e+00, 1.50477093e+00, 1.38190354e+00, 1.30021450e+00,\n",
       "       1.24548079e+00, 1.21551167e+00, 1.13885025e+00, 1.09337017e+00,\n",
       "       1.09202778e+00, 1.08163068e+00, 1.05109269e+00, 1.04355031e+00,\n",
       "       1.03007830e+00, 1.02312485e+00, 1.02276126e+00, 1.01308184e+00,\n",
       "       1.01257501e+00, 1.01143381e+00, 1.00975831e+00, 1.00770194e+00,\n",
       "       1.00134988e+00, 1.00072537e+00, 9.97699971e-01, 9.88354787e-01,\n",
       "       9.66288288e-01, 9.47163650e-01, 9.46558931e-01, 9.07722758e-01,\n",
       "       8.94304401e-01, 8.57873556e-01, 8.02778081e-01, 7.73083447e-01,\n",
       "       7.42925376e-01, 7.14438199e-01, 6.97938546e-01, 6.87357536e-01,\n",
       "       6.18771586e-01, 5.58479796e-01, 5.45428436e-01, 4.18536159e-01,\n",
       "       4.16611382e-01, 3.35066250e-01, 2.74067302e-01, 1.09542911e-01,\n",
       "       4.14082938e-02, 3.72603796e-02])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = gbc.coef_[0]\n",
    "lrimportance = pow(math.e, w)\n",
    "fi = np.argsort(-lrimportance)\n",
    "lrimportance[fi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['20TAH187mf', '14TAB024mf', '14TAH187mf', '19TAH190mf', '17TAC016kolt',\n",
       "       '20TAI037mf', '15TAH021kolt', '15TAB024mf', '16TAB024mf', '18TAH187mf',\n",
       "       '19TAH187mf', '17TAI056mf', '20TAC078kolt', '19TAB024kolt',\n",
       "       '16TAI036mf', '20TAI019mf', '16TAH044mf', '20TAC009kolt', '18TAH042mf',\n",
       "       '20TAH042mf', '15TAC015kolt', '14TAC014kolt', '15TAC011kolt',\n",
       "       '16TAH180liab', '17TAC015kolt', '14TAB024kolt', '17TAH187mf',\n",
       "       '16TAH187mf', '16TAB024kolt', '14TAC011kolt', '18TAH180liab',\n",
       "       '19TAC014kolt', '15TAH187mf', '16TAH088mf', '14TAC013kolt',\n",
       "       '15TAC013kolt', '16TAH005toke', '16TAH054liab', '17TAH187toke',\n",
       "       '19TAC013kolt', '19TAH187toke', '18TAC008kolt', '20TAC008kolt',\n",
       "       '20TAH187toke', '14TAH187toke', '17TAC018kolt', '15TAH208toke',\n",
       "       '15TAH187toke', '19TAH004toke', '17TAH189toke'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratiosCluster.columns[fi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1c33ace8490>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.RocCurveDisplay.from_predictions(testY, gbc.predict_proba(testX)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['20TAH187mf', '20TAH187toke', '20TAC009kolt', '19TAH187mf',\n",
       "       '16TAH187mf', '17TAC016kolt', '20TAC078kolt', '15TAC013kolt',\n",
       "       '17TAH187mf', '18TAH187mf', '15TAH187mf', '19TAH187toke', '14TAH187mf',\n",
       "       '14TAC013kolt', '15TAH187toke', '15TAC015kolt', '17TAH187toke',\n",
       "       '17TAC018kolt', '19TAH004toke', '14TAH187toke', '18TAC008kolt',\n",
       "       '16TAH044mf', '18TAH042mf', '20TAH042mf', '20TAC008kolt',\n",
       "       '17TAH189toke', '14TAC014kolt', '19TAC014kolt', '19TAC013kolt',\n",
       "       '17TAC015kolt', '20TAI019mf', '15TAH021kolt', '19TAH190mf',\n",
       "       '16TAH088mf', '20TAI037mf', '16TAI036mf', '15TAC011kolt',\n",
       "       '16TAB024kolt', '15TAB024mf', '16TAB024mf', '15TAH208toke',\n",
       "       '16TAH054liab', '14TAC011kolt', '14TAB024kolt', '16TAH180liab',\n",
       "       '19TAB024kolt', '14TAB024mf', '18TAH180liab', '16TAH005toke',\n",
       "       '17TAI056mf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratiosCluster.columns[fi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetLabels.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78761062 0.78914176 0.79650846 0.7910407  0.79278294 0.78850889\n",
      " 0.79040611 0.78852459 0.77943976]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(gradientResultSmoteN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
